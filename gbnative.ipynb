{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "dir_path='C:\\\\Data Science\\\\xgb_native_api\\\\Training'\n",
    "csv_file_name = 'Features_Variant_1.csv'\n",
    "df=pd.read_csv(os.path.join(dir_path,csv_file_name),header=None)\n",
    "df.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset has {} entries and {} features\".format(*df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.loc[:,:52].values, df.loc[:,53].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "# \"Learn\" the mean from the training data\n",
    "mean_train = np.mean(y_train)\n",
    "\n",
    "# Get predictions on the test set\n",
    "baseline_predictions = np.ones(y_test.shape) * mean_train\n",
    "\n",
    "# Compute MAE\n",
    "mae_baseline = mean_absolute_error(y_test, baseline_predictions)\n",
    "\n",
    "print(\"Baseline MAE is {:.2f}\".format(mae_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective':'reg:linear',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eval_metric'] = \"mae\"\n",
    "num_boost_round = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-mae:5.97478\n",
      "Will train until Test-mae hasn't improved in 10 rounds.\n",
      "[1]\tTest-mae:5.03359\n",
      "[2]\tTest-mae:4.64572\n",
      "[3]\tTest-mae:4.42331\n",
      "[4]\tTest-mae:4.39328\n",
      "[5]\tTest-mae:4.35544\n",
      "[6]\tTest-mae:4.31315\n",
      "[7]\tTest-mae:4.33087\n",
      "[8]\tTest-mae:4.37164\n",
      "[9]\tTest-mae:4.38774\n",
      "[10]\tTest-mae:4.39443\n",
      "[11]\tTest-mae:4.40661\n",
      "[12]\tTest-mae:4.39124\n",
      "[13]\tTest-mae:4.39088\n",
      "[14]\tTest-mae:4.39827\n",
      "[15]\tTest-mae:4.39104\n",
      "[16]\tTest-mae:4.40307\n",
      "Stopping. Best iteration:\n",
      "[6]\tTest-mae:4.31315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAE: 4.31 with 7 rounds\n"
     ]
    }
   ],
   "source": [
    "print(\"Best MAE: {:.2f} with {} rounds\".format(\n",
    "                 model.best_score,\n",
    "                 model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-mae-mean</th>\n",
       "      <th>test-mae-std</th>\n",
       "      <th>train-mae-mean</th>\n",
       "      <th>train-mae-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.689189</td>\n",
       "      <td>0.270149</td>\n",
       "      <td>5.604765</td>\n",
       "      <td>0.064495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.849525</td>\n",
       "      <td>0.271883</td>\n",
       "      <td>4.622477</td>\n",
       "      <td>0.065106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.468342</td>\n",
       "      <td>0.239475</td>\n",
       "      <td>4.059710</td>\n",
       "      <td>0.065772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.268584</td>\n",
       "      <td>0.224462</td>\n",
       "      <td>3.722983</td>\n",
       "      <td>0.060820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.192448</td>\n",
       "      <td>0.189762</td>\n",
       "      <td>3.510303</td>\n",
       "      <td>0.061203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.172856</td>\n",
       "      <td>0.189612</td>\n",
       "      <td>3.367213</td>\n",
       "      <td>0.061021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.157860</td>\n",
       "      <td>0.192572</td>\n",
       "      <td>3.245549</td>\n",
       "      <td>0.060276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.143254</td>\n",
       "      <td>0.194440</td>\n",
       "      <td>3.151495</td>\n",
       "      <td>0.062612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.147843</td>\n",
       "      <td>0.196197</td>\n",
       "      <td>3.082321</td>\n",
       "      <td>0.059020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.144657</td>\n",
       "      <td>0.189785</td>\n",
       "      <td>3.016803</td>\n",
       "      <td>0.057321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.151564</td>\n",
       "      <td>0.184621</td>\n",
       "      <td>2.974848</td>\n",
       "      <td>0.048560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.153975</td>\n",
       "      <td>0.192428</td>\n",
       "      <td>2.929269</td>\n",
       "      <td>0.034235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.154961</td>\n",
       "      <td>0.192741</td>\n",
       "      <td>2.900030</td>\n",
       "      <td>0.037107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.150087</td>\n",
       "      <td>0.185076</td>\n",
       "      <td>2.870198</td>\n",
       "      <td>0.039780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.156701</td>\n",
       "      <td>0.188260</td>\n",
       "      <td>2.846479</td>\n",
       "      <td>0.037792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.145404</td>\n",
       "      <td>0.184212</td>\n",
       "      <td>2.811917</td>\n",
       "      <td>0.036969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.141670</td>\n",
       "      <td>0.183382</td>\n",
       "      <td>2.791487</td>\n",
       "      <td>0.034505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.139406</td>\n",
       "      <td>0.191476</td>\n",
       "      <td>2.764857</td>\n",
       "      <td>0.032798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.134138</td>\n",
       "      <td>0.196838</td>\n",
       "      <td>2.730498</td>\n",
       "      <td>0.030304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.120616</td>\n",
       "      <td>0.194074</td>\n",
       "      <td>2.686291</td>\n",
       "      <td>0.025828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.115625</td>\n",
       "      <td>0.190053</td>\n",
       "      <td>2.661713</td>\n",
       "      <td>0.024625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.111492</td>\n",
       "      <td>0.195630</td>\n",
       "      <td>2.632685</td>\n",
       "      <td>0.026922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.106884</td>\n",
       "      <td>0.188216</td>\n",
       "      <td>2.598391</td>\n",
       "      <td>0.026591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.109425</td>\n",
       "      <td>0.189713</td>\n",
       "      <td>2.575809</td>\n",
       "      <td>0.034930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.106895</td>\n",
       "      <td>0.185098</td>\n",
       "      <td>2.544730</td>\n",
       "      <td>0.030703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.103488</td>\n",
       "      <td>0.185234</td>\n",
       "      <td>2.525501</td>\n",
       "      <td>0.031801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.098627</td>\n",
       "      <td>0.186998</td>\n",
       "      <td>2.500908</td>\n",
       "      <td>0.027606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.098459</td>\n",
       "      <td>0.185767</td>\n",
       "      <td>2.478799</td>\n",
       "      <td>0.029692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.098721</td>\n",
       "      <td>0.186931</td>\n",
       "      <td>2.457476</td>\n",
       "      <td>0.027944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.093534</td>\n",
       "      <td>0.187031</td>\n",
       "      <td>2.433839</td>\n",
       "      <td>0.019612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.092398</td>\n",
       "      <td>0.190349</td>\n",
       "      <td>2.413498</td>\n",
       "      <td>0.019445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4.092814</td>\n",
       "      <td>0.189468</td>\n",
       "      <td>2.398102</td>\n",
       "      <td>0.020367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4.094014</td>\n",
       "      <td>0.191986</td>\n",
       "      <td>2.373646</td>\n",
       "      <td>0.023400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4.090828</td>\n",
       "      <td>0.183624</td>\n",
       "      <td>2.354041</td>\n",
       "      <td>0.021126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4.091551</td>\n",
       "      <td>0.183067</td>\n",
       "      <td>2.341457</td>\n",
       "      <td>0.014121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4.092410</td>\n",
       "      <td>0.179464</td>\n",
       "      <td>2.325629</td>\n",
       "      <td>0.011132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4.086722</td>\n",
       "      <td>0.183275</td>\n",
       "      <td>2.307251</td>\n",
       "      <td>0.014028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4.082788</td>\n",
       "      <td>0.184458</td>\n",
       "      <td>2.292440</td>\n",
       "      <td>0.011218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test-mae-mean  test-mae-std  train-mae-mean  train-mae-std\n",
       "0        5.689189      0.270149        5.604765       0.064495\n",
       "1        4.849525      0.271883        4.622477       0.065106\n",
       "2        4.468342      0.239475        4.059710       0.065772\n",
       "3        4.268584      0.224462        3.722983       0.060820\n",
       "4        4.192448      0.189762        3.510303       0.061203\n",
       "5        4.172856      0.189612        3.367213       0.061021\n",
       "6        4.157860      0.192572        3.245549       0.060276\n",
       "7        4.143254      0.194440        3.151495       0.062612\n",
       "8        4.147843      0.196197        3.082321       0.059020\n",
       "9        4.144657      0.189785        3.016803       0.057321\n",
       "10       4.151564      0.184621        2.974848       0.048560\n",
       "11       4.153975      0.192428        2.929269       0.034235\n",
       "12       4.154961      0.192741        2.900030       0.037107\n",
       "13       4.150087      0.185076        2.870198       0.039780\n",
       "14       4.156701      0.188260        2.846479       0.037792\n",
       "15       4.145404      0.184212        2.811917       0.036969\n",
       "16       4.141670      0.183382        2.791487       0.034505\n",
       "17       4.139406      0.191476        2.764857       0.032798\n",
       "18       4.134138      0.196838        2.730498       0.030304\n",
       "19       4.120616      0.194074        2.686291       0.025828\n",
       "20       4.115625      0.190053        2.661713       0.024625\n",
       "21       4.111492      0.195630        2.632685       0.026922\n",
       "22       4.106884      0.188216        2.598391       0.026591\n",
       "23       4.109425      0.189713        2.575809       0.034930\n",
       "24       4.106895      0.185098        2.544730       0.030703\n",
       "25       4.103488      0.185234        2.525501       0.031801\n",
       "26       4.098627      0.186998        2.500908       0.027606\n",
       "27       4.098459      0.185767        2.478799       0.029692\n",
       "28       4.098721      0.186931        2.457476       0.027944\n",
       "29       4.093534      0.187031        2.433839       0.019612\n",
       "30       4.092398      0.190349        2.413498       0.019445\n",
       "31       4.092814      0.189468        2.398102       0.020367\n",
       "32       4.094014      0.191986        2.373646       0.023400\n",
       "33       4.090828      0.183624        2.354041       0.021126\n",
       "34       4.091551      0.183067        2.341457       0.014121\n",
       "35       4.092410      0.179464        2.325629       0.011132\n",
       "36       4.086722      0.183275        2.307251       0.014028\n",
       "37       4.082788      0.184458        2.292440       0.011218"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'mae'},\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0827876000000005"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test-mae-mean'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can try wider intervals with a larger step between\n",
    "# each value and then narrow it down. Here after several\n",
    "# iteration I found that the optimal value was in the\n",
    "# following ranges.\n",
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(9,12)\n",
    "    for min_child_weight in range(5,8)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=9, min_child_weight=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moisessalazar77\\Anaconda3\\envs\\regression_competition\\lib\\site-packages\\ipykernel\\__main__.py:26: FutureWarning: 'argmin' is deprecated. Use 'idxmin' instead. The behavior of 'argmin' will be corrected to return the positional minimum in the future. Use 'series.values.argmin' to get the position of the minimum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMAE 4.04524 for 6 rounds\n",
      "CV with max_depth=9, min_child_weight=6\n",
      "\tMAE 4.0764622 for 5 rounds\n",
      "CV with max_depth=9, min_child_weight=7\n",
      "\tMAE 4.0753928 for 5 rounds\n",
      "CV with max_depth=10, min_child_weight=5\n",
      "\tMAE 4.0805826000000005 for 5 rounds\n",
      "CV with max_depth=10, min_child_weight=6\n",
      "\tMAE 4.035100600000001 for 5 rounds\n",
      "CV with max_depth=10, min_child_weight=7\n",
      "\tMAE 4.0872416000000005 for 5 rounds\n",
      "CV with max_depth=11, min_child_weight=5\n",
      "\tMAE 4.062633 for 5 rounds\n",
      "CV with max_depth=11, min_child_weight=6\n",
      "\tMAE 4.054831999999999 for 5 rounds\n",
      "CV with max_depth=11, min_child_weight=7\n",
      "\tMAE 4.0581036 for 5 rounds\n",
      "Best params: 10, 6, MAE: 4.035100600000001\n"
     ]
    }
   ],
   "source": [
    "# Define initial best params and MAE\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "\n",
    "    # Update best MAE\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = 10\n",
    "params['min_child_weight'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=1.0, colsample=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moisessalazar77\\Anaconda3\\envs\\regression_competition\\lib\\site-packages\\ipykernel\\__main__.py:27: FutureWarning: 'argmin' is deprecated. Use 'idxmin' instead. The behavior of 'argmin' will be corrected to return the positional minimum in the future. Use 'series.values.argmin' to get the position of the minimum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMAE 4.035100600000001 for 5 rounds\n",
      "CV with subsample=1.0, colsample=0.9\n",
      "\tMAE 4.053543 for 5 rounds\n",
      "CV with subsample=1.0, colsample=0.8\n",
      "\tMAE 4.0752204 for 5 rounds\n",
      "CV with subsample=1.0, colsample=0.7\n",
      "\tMAE 4.126817600000001 for 5 rounds\n",
      "CV with subsample=0.9, colsample=1.0\n",
      "\tMAE 4.0747636 for 6 rounds\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "\tMAE 4.301792 for 5 rounds\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "\tMAE 4.2715806 for 4 rounds\n",
      "CV with subsample=0.9, colsample=0.7\n",
      "\tMAE 4.4203404 for 11 rounds\n",
      "CV with subsample=0.8, colsample=1.0\n",
      "\tMAE 4.058284800000001 for 5 rounds\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "\tMAE 4.3079596 for 7 rounds\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "\tMAE 4.3022836 for 4 rounds\n",
      "CV with subsample=0.8, colsample=0.7\n",
      "\tMAE 4.419911600000001 for 8 rounds\n",
      "CV with subsample=0.7, colsample=1.0\n",
      "\tMAE 4.0859668 for 5 rounds\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "\tMAE 4.2999216 for 8 rounds\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "\tMAE 4.3593908 for 7 rounds\n",
      "CV with subsample=0.7, colsample=0.7\n",
      "\tMAE 4.4839162 for 8 rounds\n",
      "Best params: 1.0, 1.0, MAE: 4.035100600000001\n"
     ]
    }
   ],
   "source": [
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "\n",
    "    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)\n",
    "\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "CV with eta=0.3\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moisessalazar77\\Anaconda3\\envs\\regression_competition\\lib\\site-packages\\ipykernel\\__main__.py:26: FutureWarning: 'argmin' is deprecated. Use 'idxmin' instead. The behavior of 'argmin' will be corrected to return the positional minimum in the future. Use 'series.values.argmin' to get the position of the minimum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMAE 4.4839162 for 8 rounds\n",
      "\n",
      "Best params: 0.3, MAE: 4.4839162\n",
      "CV with eta=0.2\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moisessalazar77\\Anaconda3\\envs\\regression_competition\\lib\\site-packages\\ipykernel\\__main__.py:26: FutureWarning: 'argmin' is deprecated. Use 'idxmin' instead. The behavior of 'argmin' will be corrected to return the positional minimum in the future. Use 'series.values.argmin' to get the position of the minimum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMAE 4.322296 for 12 rounds\n",
      "\n",
      "Best params: 0.2, MAE: 4.322296\n",
      "CV with eta=0.1\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moisessalazar77\\Anaconda3\\envs\\regression_competition\\lib\\site-packages\\ipykernel\\__main__.py:26: FutureWarning: 'argmin' is deprecated. Use 'idxmin' instead. The behavior of 'argmin' will be corrected to return the positional minimum in the future. Use 'series.values.argmin' to get the position of the minimum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMAE 4.0556636 for 25 rounds\n",
      "\n",
      "Best params: 0.1, MAE: 4.0556636\n",
      "CV with eta=0.05\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moisessalazar77\\Anaconda3\\envs\\regression_competition\\lib\\site-packages\\ipykernel\\__main__.py:26: FutureWarning: 'argmin' is deprecated. Use 'idxmin' instead. The behavior of 'argmin' will be corrected to return the positional minimum in the future. Use 'series.values.argmin' to get the position of the minimum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMAE 3.9623722 for 55 rounds\n",
      "\n",
      "Best params: 0.05, MAE: 3.9623722\n",
      "CV with eta=0.01\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moisessalazar77\\Anaconda3\\envs\\regression_competition\\lib\\site-packages\\ipykernel\\__main__.py:26: FutureWarning: 'argmin' is deprecated. Use 'idxmin' instead. The behavior of 'argmin' will be corrected to return the positional minimum in the future. Use 'series.values.argmin' to get the position of the minimum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMAE 3.895253399999999 for 269 rounds\n",
      "\n",
      "Best params: 0.01, MAE: 3.895253399999999\n",
      "CV with eta=0.005\n",
      "Wall time: 0 ns\n",
      "\tMAE 3.8831075999999998 for 530 rounds\n",
      "\n",
      "Best params: 0.005, MAE: 3.8831075999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moisessalazar77\\Anaconda3\\envs\\regression_competition\\lib\\site-packages\\ipykernel\\__main__.py:26: FutureWarning: 'argmin' is deprecated. Use 'idxmin' instead. The behavior of 'argmin' will be corrected to return the positional minimum in the future. Use 'series.values.argmin' to get the position of the minimum now.\n"
     ]
    }
   ],
   "source": [
    "# This can take some timeâ€¦\n",
    "%time\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "\n",
    "    # We update our parameters\n",
    "    params['eta'] = eta\n",
    "\n",
    "# Run and time CV\n",
    "    %time \n",
    "    cv_results = xgb.cv(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=num_boost_round,\n",
    "            seed=42,\n",
    "            nfold=5,\n",
    "            metrics=['mae'],\n",
    "            early_stopping_rounds=10\n",
    "          )\n",
    "\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\\n\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = eta\n",
    "\n",
    "    print(\"Best params: {}, MAE: {}\".format(best_params, min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eta'] = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-mae:7.69225\n",
      "Will train until Test-mae hasn't improved in 10 rounds.\n",
      "[1]\tTest-mae:7.62402\n",
      "[2]\tTest-mae:7.56704\n",
      "[3]\tTest-mae:7.5034\n",
      "[4]\tTest-mae:7.43531\n",
      "[5]\tTest-mae:7.37917\n",
      "[6]\tTest-mae:7.31423\n",
      "[7]\tTest-mae:7.25928\n",
      "[8]\tTest-mae:7.20004\n",
      "[9]\tTest-mae:7.14086\n",
      "[10]\tTest-mae:7.08814\n",
      "[11]\tTest-mae:7.03727\n",
      "[12]\tTest-mae:6.99024\n",
      "[13]\tTest-mae:6.94458\n",
      "[14]\tTest-mae:6.88791\n",
      "[15]\tTest-mae:6.8311\n",
      "[16]\tTest-mae:6.78486\n",
      "[17]\tTest-mae:6.72895\n",
      "[18]\tTest-mae:6.68487\n",
      "[19]\tTest-mae:6.63521\n",
      "[20]\tTest-mae:6.5867\n",
      "[21]\tTest-mae:6.53298\n",
      "[22]\tTest-mae:6.48231\n",
      "[23]\tTest-mae:6.44161\n",
      "[24]\tTest-mae:6.39147\n",
      "[25]\tTest-mae:6.34277\n",
      "[26]\tTest-mae:6.29427\n",
      "[27]\tTest-mae:6.24632\n",
      "[28]\tTest-mae:6.19971\n",
      "[29]\tTest-mae:6.16322\n",
      "[30]\tTest-mae:6.11903\n",
      "[31]\tTest-mae:6.07511\n",
      "[32]\tTest-mae:6.0299\n",
      "[33]\tTest-mae:5.98261\n",
      "[34]\tTest-mae:5.93708\n",
      "[35]\tTest-mae:5.8973\n",
      "[36]\tTest-mae:5.85705\n",
      "[37]\tTest-mae:5.815\n",
      "[38]\tTest-mae:5.77409\n",
      "[39]\tTest-mae:5.73228\n",
      "[40]\tTest-mae:5.69574\n",
      "[41]\tTest-mae:5.6606\n",
      "[42]\tTest-mae:5.62511\n",
      "[43]\tTest-mae:5.59235\n",
      "[44]\tTest-mae:5.55786\n",
      "[45]\tTest-mae:5.53048\n",
      "[46]\tTest-mae:5.50056\n",
      "[47]\tTest-mae:5.47085\n",
      "[48]\tTest-mae:5.44553\n",
      "[49]\tTest-mae:5.41301\n",
      "[50]\tTest-mae:5.3867\n",
      "[51]\tTest-mae:5.3507\n",
      "[52]\tTest-mae:5.3266\n",
      "[53]\tTest-mae:5.29482\n",
      "[54]\tTest-mae:5.26264\n",
      "[55]\tTest-mae:5.24144\n",
      "[56]\tTest-mae:5.21986\n",
      "[57]\tTest-mae:5.19232\n",
      "[58]\tTest-mae:5.16319\n",
      "[59]\tTest-mae:5.13728\n",
      "[60]\tTest-mae:5.11003\n",
      "[61]\tTest-mae:5.08103\n",
      "[62]\tTest-mae:5.0515\n",
      "[63]\tTest-mae:5.02315\n",
      "[64]\tTest-mae:4.99606\n",
      "[65]\tTest-mae:4.97501\n",
      "[66]\tTest-mae:4.94984\n",
      "[67]\tTest-mae:4.92452\n",
      "[68]\tTest-mae:4.89993\n",
      "[69]\tTest-mae:4.87936\n",
      "[70]\tTest-mae:4.85587\n",
      "[71]\tTest-mae:4.83823\n",
      "[72]\tTest-mae:4.81477\n",
      "[73]\tTest-mae:4.79333\n",
      "[74]\tTest-mae:4.7728\n",
      "[75]\tTest-mae:4.75314\n",
      "[76]\tTest-mae:4.73758\n",
      "[77]\tTest-mae:4.71674\n",
      "[78]\tTest-mae:4.69604\n",
      "[79]\tTest-mae:4.67418\n",
      "[80]\tTest-mae:4.65374\n",
      "[81]\tTest-mae:4.63274\n",
      "[82]\tTest-mae:4.61474\n",
      "[83]\tTest-mae:4.59542\n",
      "[84]\tTest-mae:4.57686\n",
      "[85]\tTest-mae:4.55899\n",
      "[86]\tTest-mae:4.54773\n",
      "[87]\tTest-mae:4.53278\n",
      "[88]\tTest-mae:4.51712\n",
      "[89]\tTest-mae:4.50703\n",
      "[90]\tTest-mae:4.49105\n",
      "[91]\tTest-mae:4.47255\n",
      "[92]\tTest-mae:4.46392\n",
      "[93]\tTest-mae:4.45436\n",
      "[94]\tTest-mae:4.43933\n",
      "[95]\tTest-mae:4.42532\n",
      "[96]\tTest-mae:4.41747\n",
      "[97]\tTest-mae:4.40155\n",
      "[98]\tTest-mae:4.38769\n",
      "[99]\tTest-mae:4.37616\n",
      "[100]\tTest-mae:4.36456\n",
      "[101]\tTest-mae:4.35205\n",
      "[102]\tTest-mae:4.33924\n",
      "[103]\tTest-mae:4.32707\n",
      "[104]\tTest-mae:4.31347\n",
      "[105]\tTest-mae:4.30293\n",
      "[106]\tTest-mae:4.2936\n",
      "[107]\tTest-mae:4.28165\n",
      "[108]\tTest-mae:4.27581\n",
      "[109]\tTest-mae:4.27233\n",
      "[110]\tTest-mae:4.26062\n",
      "[111]\tTest-mae:4.24997\n",
      "[112]\tTest-mae:4.24409\n",
      "[113]\tTest-mae:4.23457\n",
      "[114]\tTest-mae:4.23045\n",
      "[115]\tTest-mae:4.22215\n",
      "[116]\tTest-mae:4.21213\n",
      "[117]\tTest-mae:4.20213\n",
      "[118]\tTest-mae:4.19359\n",
      "[119]\tTest-mae:4.19057\n",
      "[120]\tTest-mae:4.18025\n",
      "[121]\tTest-mae:4.17618\n",
      "[122]\tTest-mae:4.1644\n",
      "[123]\tTest-mae:4.16027\n",
      "[124]\tTest-mae:4.15161\n",
      "[125]\tTest-mae:4.14322\n",
      "[126]\tTest-mae:4.13645\n",
      "[127]\tTest-mae:4.13411\n",
      "[128]\tTest-mae:4.12998\n",
      "[129]\tTest-mae:4.12434\n",
      "[130]\tTest-mae:4.1177\n",
      "[131]\tTest-mae:4.11419\n",
      "[132]\tTest-mae:4.10529\n",
      "[133]\tTest-mae:4.10468\n",
      "[134]\tTest-mae:4.09586\n",
      "[135]\tTest-mae:4.08608\n",
      "[136]\tTest-mae:4.07821\n",
      "[137]\tTest-mae:4.07353\n",
      "[138]\tTest-mae:4.0671\n",
      "[139]\tTest-mae:4.0618\n",
      "[140]\tTest-mae:4.05884\n",
      "[141]\tTest-mae:4.05292\n",
      "[142]\tTest-mae:4.04594\n",
      "[143]\tTest-mae:4.03838\n",
      "[144]\tTest-mae:4.03136\n",
      "[145]\tTest-mae:4.02355\n",
      "[146]\tTest-mae:4.01503\n",
      "[147]\tTest-mae:4.01087\n",
      "[148]\tTest-mae:4.01064\n",
      "[149]\tTest-mae:4.00997\n",
      "[150]\tTest-mae:4.00637\n",
      "[151]\tTest-mae:4.0036\n",
      "[152]\tTest-mae:3.99847\n",
      "[153]\tTest-mae:3.99396\n",
      "[154]\tTest-mae:3.98945\n",
      "[155]\tTest-mae:3.98212\n",
      "[156]\tTest-mae:3.97653\n",
      "[157]\tTest-mae:3.97332\n",
      "[158]\tTest-mae:3.96798\n",
      "[159]\tTest-mae:3.965\n",
      "[160]\tTest-mae:3.96088\n",
      "[161]\tTest-mae:3.96158\n",
      "[162]\tTest-mae:3.95698\n",
      "[163]\tTest-mae:3.95451\n",
      "[164]\tTest-mae:3.95043\n",
      "[165]\tTest-mae:3.94786\n",
      "[166]\tTest-mae:3.94566\n",
      "[167]\tTest-mae:3.94304\n",
      "[168]\tTest-mae:3.939\n",
      "[169]\tTest-mae:3.93719\n",
      "[170]\tTest-mae:3.93238\n",
      "[171]\tTest-mae:3.93068\n",
      "[172]\tTest-mae:3.92652\n",
      "[173]\tTest-mae:3.92508\n",
      "[174]\tTest-mae:3.92287\n",
      "[175]\tTest-mae:3.92148\n",
      "[176]\tTest-mae:3.92096\n",
      "[177]\tTest-mae:3.91673\n",
      "[178]\tTest-mae:3.91597\n",
      "[179]\tTest-mae:3.91413\n",
      "[180]\tTest-mae:3.91359\n",
      "[181]\tTest-mae:3.91198\n",
      "[182]\tTest-mae:3.91204\n",
      "[183]\tTest-mae:3.91183\n",
      "[184]\tTest-mae:3.91207\n",
      "[185]\tTest-mae:3.90965\n",
      "[186]\tTest-mae:3.9083\n",
      "[187]\tTest-mae:3.90499\n",
      "[188]\tTest-mae:3.90578\n",
      "[189]\tTest-mae:3.9039\n",
      "[190]\tTest-mae:3.90445\n",
      "[191]\tTest-mae:3.903\n",
      "[192]\tTest-mae:3.90128\n",
      "[193]\tTest-mae:3.89962\n",
      "[194]\tTest-mae:3.89734\n",
      "[195]\tTest-mae:3.8941\n",
      "[196]\tTest-mae:3.8944\n",
      "[197]\tTest-mae:3.89334\n",
      "[198]\tTest-mae:3.89114\n",
      "[199]\tTest-mae:3.89176\n",
      "[200]\tTest-mae:3.89145\n",
      "[201]\tTest-mae:3.8922\n",
      "[202]\tTest-mae:3.89193\n",
      "[203]\tTest-mae:3.89177\n",
      "[204]\tTest-mae:3.89372\n",
      "[205]\tTest-mae:3.89366\n",
      "[206]\tTest-mae:3.89214\n",
      "[207]\tTest-mae:3.89218\n",
      "[208]\tTest-mae:3.89078\n",
      "[209]\tTest-mae:3.89146\n",
      "[210]\tTest-mae:3.88981\n",
      "[211]\tTest-mae:3.89027\n",
      "[212]\tTest-mae:3.88909\n",
      "[213]\tTest-mae:3.88897\n",
      "[214]\tTest-mae:3.88923\n",
      "[215]\tTest-mae:3.89045\n",
      "[216]\tTest-mae:3.89158\n",
      "[217]\tTest-mae:3.8926\n",
      "[218]\tTest-mae:3.89124\n",
      "[219]\tTest-mae:3.89211\n",
      "[220]\tTest-mae:3.89243\n",
      "[221]\tTest-mae:3.89033\n",
      "[222]\tTest-mae:3.89197\n",
      "[223]\tTest-mae:3.89122\n",
      "Stopping. Best iteration:\n",
      "[213]\tTest-mae:3.88897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAE: 3.89 in 214 rounds\n"
     ]
    }
   ],
   "source": [
    "print(\"Best MAE: {:.2f} in {} rounds\".format(model.best_score, model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-mae:7.69225\n",
      "[1]\tTest-mae:7.62402\n",
      "[2]\tTest-mae:7.56704\n",
      "[3]\tTest-mae:7.5034\n",
      "[4]\tTest-mae:7.43531\n",
      "[5]\tTest-mae:7.37917\n",
      "[6]\tTest-mae:7.31423\n",
      "[7]\tTest-mae:7.25928\n",
      "[8]\tTest-mae:7.20004\n",
      "[9]\tTest-mae:7.14086\n",
      "[10]\tTest-mae:7.08814\n",
      "[11]\tTest-mae:7.03727\n",
      "[12]\tTest-mae:6.99024\n",
      "[13]\tTest-mae:6.94458\n",
      "[14]\tTest-mae:6.88791\n",
      "[15]\tTest-mae:6.8311\n",
      "[16]\tTest-mae:6.78486\n",
      "[17]\tTest-mae:6.72895\n",
      "[18]\tTest-mae:6.68487\n",
      "[19]\tTest-mae:6.63521\n",
      "[20]\tTest-mae:6.5867\n",
      "[21]\tTest-mae:6.53298\n",
      "[22]\tTest-mae:6.48231\n",
      "[23]\tTest-mae:6.44161\n",
      "[24]\tTest-mae:6.39147\n",
      "[25]\tTest-mae:6.34277\n",
      "[26]\tTest-mae:6.29427\n",
      "[27]\tTest-mae:6.24632\n",
      "[28]\tTest-mae:6.19971\n",
      "[29]\tTest-mae:6.16322\n",
      "[30]\tTest-mae:6.11903\n",
      "[31]\tTest-mae:6.07511\n",
      "[32]\tTest-mae:6.0299\n",
      "[33]\tTest-mae:5.98261\n",
      "[34]\tTest-mae:5.93708\n",
      "[35]\tTest-mae:5.8973\n",
      "[36]\tTest-mae:5.85705\n",
      "[37]\tTest-mae:5.815\n",
      "[38]\tTest-mae:5.77409\n",
      "[39]\tTest-mae:5.73228\n",
      "[40]\tTest-mae:5.69574\n",
      "[41]\tTest-mae:5.6606\n",
      "[42]\tTest-mae:5.62511\n",
      "[43]\tTest-mae:5.59235\n",
      "[44]\tTest-mae:5.55786\n",
      "[45]\tTest-mae:5.53048\n",
      "[46]\tTest-mae:5.50056\n",
      "[47]\tTest-mae:5.47085\n",
      "[48]\tTest-mae:5.44553\n",
      "[49]\tTest-mae:5.41301\n",
      "[50]\tTest-mae:5.3867\n",
      "[51]\tTest-mae:5.3507\n",
      "[52]\tTest-mae:5.3266\n",
      "[53]\tTest-mae:5.29482\n",
      "[54]\tTest-mae:5.26264\n",
      "[55]\tTest-mae:5.24144\n",
      "[56]\tTest-mae:5.21986\n",
      "[57]\tTest-mae:5.19232\n",
      "[58]\tTest-mae:5.16319\n",
      "[59]\tTest-mae:5.13728\n",
      "[60]\tTest-mae:5.11003\n",
      "[61]\tTest-mae:5.08103\n",
      "[62]\tTest-mae:5.0515\n",
      "[63]\tTest-mae:5.02315\n",
      "[64]\tTest-mae:4.99606\n",
      "[65]\tTest-mae:4.97501\n",
      "[66]\tTest-mae:4.94984\n",
      "[67]\tTest-mae:4.92452\n",
      "[68]\tTest-mae:4.89993\n",
      "[69]\tTest-mae:4.87936\n",
      "[70]\tTest-mae:4.85587\n",
      "[71]\tTest-mae:4.83823\n",
      "[72]\tTest-mae:4.81477\n",
      "[73]\tTest-mae:4.79333\n",
      "[74]\tTest-mae:4.7728\n",
      "[75]\tTest-mae:4.75314\n",
      "[76]\tTest-mae:4.73758\n",
      "[77]\tTest-mae:4.71674\n",
      "[78]\tTest-mae:4.69604\n",
      "[79]\tTest-mae:4.67418\n",
      "[80]\tTest-mae:4.65374\n",
      "[81]\tTest-mae:4.63274\n",
      "[82]\tTest-mae:4.61474\n",
      "[83]\tTest-mae:4.59542\n",
      "[84]\tTest-mae:4.57686\n",
      "[85]\tTest-mae:4.55899\n",
      "[86]\tTest-mae:4.54773\n",
      "[87]\tTest-mae:4.53278\n",
      "[88]\tTest-mae:4.51712\n",
      "[89]\tTest-mae:4.50703\n",
      "[90]\tTest-mae:4.49105\n",
      "[91]\tTest-mae:4.47255\n",
      "[92]\tTest-mae:4.46392\n",
      "[93]\tTest-mae:4.45436\n",
      "[94]\tTest-mae:4.43933\n",
      "[95]\tTest-mae:4.42532\n",
      "[96]\tTest-mae:4.41747\n",
      "[97]\tTest-mae:4.40155\n",
      "[98]\tTest-mae:4.38769\n",
      "[99]\tTest-mae:4.37616\n",
      "[100]\tTest-mae:4.36456\n",
      "[101]\tTest-mae:4.35205\n",
      "[102]\tTest-mae:4.33924\n",
      "[103]\tTest-mae:4.32707\n",
      "[104]\tTest-mae:4.31347\n",
      "[105]\tTest-mae:4.30293\n",
      "[106]\tTest-mae:4.2936\n",
      "[107]\tTest-mae:4.28165\n",
      "[108]\tTest-mae:4.27581\n",
      "[109]\tTest-mae:4.27233\n",
      "[110]\tTest-mae:4.26062\n",
      "[111]\tTest-mae:4.24997\n",
      "[112]\tTest-mae:4.24409\n",
      "[113]\tTest-mae:4.23457\n",
      "[114]\tTest-mae:4.23045\n",
      "[115]\tTest-mae:4.22215\n",
      "[116]\tTest-mae:4.21213\n",
      "[117]\tTest-mae:4.20213\n",
      "[118]\tTest-mae:4.19359\n",
      "[119]\tTest-mae:4.19057\n",
      "[120]\tTest-mae:4.18025\n",
      "[121]\tTest-mae:4.17618\n",
      "[122]\tTest-mae:4.1644\n",
      "[123]\tTest-mae:4.16027\n",
      "[124]\tTest-mae:4.15161\n",
      "[125]\tTest-mae:4.14322\n",
      "[126]\tTest-mae:4.13645\n",
      "[127]\tTest-mae:4.13411\n",
      "[128]\tTest-mae:4.12998\n",
      "[129]\tTest-mae:4.12434\n",
      "[130]\tTest-mae:4.1177\n",
      "[131]\tTest-mae:4.11419\n",
      "[132]\tTest-mae:4.10529\n",
      "[133]\tTest-mae:4.10468\n",
      "[134]\tTest-mae:4.09586\n",
      "[135]\tTest-mae:4.08608\n",
      "[136]\tTest-mae:4.07821\n",
      "[137]\tTest-mae:4.07353\n",
      "[138]\tTest-mae:4.0671\n",
      "[139]\tTest-mae:4.0618\n",
      "[140]\tTest-mae:4.05884\n",
      "[141]\tTest-mae:4.05292\n",
      "[142]\tTest-mae:4.04594\n",
      "[143]\tTest-mae:4.03838\n",
      "[144]\tTest-mae:4.03136\n",
      "[145]\tTest-mae:4.02355\n",
      "[146]\tTest-mae:4.01503\n",
      "[147]\tTest-mae:4.01087\n",
      "[148]\tTest-mae:4.01064\n",
      "[149]\tTest-mae:4.00997\n",
      "[150]\tTest-mae:4.00637\n",
      "[151]\tTest-mae:4.0036\n",
      "[152]\tTest-mae:3.99847\n",
      "[153]\tTest-mae:3.99396\n",
      "[154]\tTest-mae:3.98945\n",
      "[155]\tTest-mae:3.98212\n",
      "[156]\tTest-mae:3.97653\n",
      "[157]\tTest-mae:3.97332\n",
      "[158]\tTest-mae:3.96798\n",
      "[159]\tTest-mae:3.965\n",
      "[160]\tTest-mae:3.96088\n",
      "[161]\tTest-mae:3.96158\n",
      "[162]\tTest-mae:3.95698\n",
      "[163]\tTest-mae:3.95451\n",
      "[164]\tTest-mae:3.95043\n",
      "[165]\tTest-mae:3.94786\n",
      "[166]\tTest-mae:3.94566\n",
      "[167]\tTest-mae:3.94304\n",
      "[168]\tTest-mae:3.939\n",
      "[169]\tTest-mae:3.93719\n",
      "[170]\tTest-mae:3.93238\n",
      "[171]\tTest-mae:3.93068\n",
      "[172]\tTest-mae:3.92652\n",
      "[173]\tTest-mae:3.92508\n",
      "[174]\tTest-mae:3.92287\n",
      "[175]\tTest-mae:3.92148\n",
      "[176]\tTest-mae:3.92096\n",
      "[177]\tTest-mae:3.91673\n",
      "[178]\tTest-mae:3.91597\n",
      "[179]\tTest-mae:3.91413\n",
      "[180]\tTest-mae:3.91359\n",
      "[181]\tTest-mae:3.91198\n",
      "[182]\tTest-mae:3.91204\n",
      "[183]\tTest-mae:3.91183\n",
      "[184]\tTest-mae:3.91207\n",
      "[185]\tTest-mae:3.90965\n",
      "[186]\tTest-mae:3.9083\n",
      "[187]\tTest-mae:3.90499\n",
      "[188]\tTest-mae:3.90578\n",
      "[189]\tTest-mae:3.9039\n",
      "[190]\tTest-mae:3.90445\n",
      "[191]\tTest-mae:3.903\n",
      "[192]\tTest-mae:3.90128\n",
      "[193]\tTest-mae:3.89962\n",
      "[194]\tTest-mae:3.89734\n",
      "[195]\tTest-mae:3.8941\n",
      "[196]\tTest-mae:3.8944\n",
      "[197]\tTest-mae:3.89334\n",
      "[198]\tTest-mae:3.89114\n",
      "[199]\tTest-mae:3.89176\n",
      "[200]\tTest-mae:3.89145\n",
      "[201]\tTest-mae:3.8922\n",
      "[202]\tTest-mae:3.89193\n",
      "[203]\tTest-mae:3.89177\n",
      "[204]\tTest-mae:3.89372\n",
      "[205]\tTest-mae:3.89366\n",
      "[206]\tTest-mae:3.89214\n",
      "[207]\tTest-mae:3.89218\n",
      "[208]\tTest-mae:3.89078\n",
      "[209]\tTest-mae:3.89146\n",
      "[210]\tTest-mae:3.88981\n",
      "[211]\tTest-mae:3.89027\n",
      "[212]\tTest-mae:3.88909\n",
      "[213]\tTest-mae:3.88897\n"
     ]
    }
   ],
   "source": [
    "num_boost_round = model.best_iteration + 1\n",
    "\n",
    "best_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8889745183475544"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(best_model.predict(dtest), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save_model(\"my_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.7648475 , 0.30940798, 1.8136443 , ..., 3.2530515 , 0.09870756,\n",
       "       3.8920937 ], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = xgb.Booster()\n",
    "loaded_model.load_model(\"my_model.model\")\n",
    "\n",
    "# And use it for predictions.\n",
    "loaded_model.predict(dtest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:regression_competition]",
   "language": "python",
   "name": "conda-env-regression_competition-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
